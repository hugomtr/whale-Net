{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-V4MQZPGDkL",
        "outputId": "cf68f8a7-063a-43dc-9a22-ebe08cd5c532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_local_drive='/content/gdrive/My\\ Drive/TER/WhaleFaceNet/'\n",
        "# Ajout du path pour les librairies, fonctions et données\n",
        "sys.path.append(my_local_drive)\n",
        "# Se positionner sur le répertoire associé\n",
        "%cd $my_local_drive\n",
        "\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "5DAN34-YGJQP",
        "outputId": "99c8f674-6f7c-47fe-af02-5f562521d28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/TER/WhaleFaceNet\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/TER/WhaleFaceNet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mydnC_rQF3Kq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import skimage as sk\n",
        "\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import skimage as sk\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K\n",
        "from math import isnan\n",
        "from tqdm import tqdm_notebook\n",
        "from helper_functions import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "c = np.random.randint(10, size=50)"
      ],
      "metadata": {
        "id": "Xk4cMkdXXywL"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHb8OUoGF3Kw"
      },
      "outputs": [],
      "source": [
        "PATH = 'adata/'\n",
        "PATH_MODEL = 'output/model/'\n",
        "PATH_SAVE = 'output/save/'\n",
        "SIZE        = (128,128,3)                           # taille des images en entrée\n",
        "VALID_SPLIT  = 0.3    \n",
        "LOAD_NET    = False                                 # Chargement du réseau\n",
        "NET_NAME    = 'whaleFaceNet'                        # Network saved name\n",
        "NBOF_EPOCHS = 250                                     # Number of epoch to train the network\n",
        "START_EPOCH = 0\n",
        "STEPS_PER_EPOCH = 150                                # Number of steps per epoch\n",
        "VALIDATION_STEPS = 30   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On aura préalablement \"augmenté\" le jeu de donnés de manière à avoir au moins 2 photos par individus\n",
        "\n"
      ],
      "metadata": {
        "id": "KxsIxiVZf2ox"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnQ-p41nF3Ky",
        "outputId": "7eb1519e-95df-469f-d40e-2d9d751a5dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement dataset...\n",
            "Done.\n",
            "Total nombres d'images importés: 4789\n",
            "Total nombre de classes: 447\n"
          ]
        }
      ],
      "source": [
        "assert os.path.isdir(PATH), '[Error] Provided PATH for dataset does not exist.'\n",
        "\n",
        "print('Chargement dataset...')\n",
        "\n",
        "filenames = np.empty(0)\n",
        "labels = np.empty(0)\n",
        "idx = 0\n",
        "for root,dirs,files in os.walk(PATH):\n",
        "    if len(files)>1:\n",
        "        for i in range(len(files)):\n",
        "            files[i] = root + '/' + files[i]\n",
        "        filenames = np.append(filenames,files)\n",
        "        labels = np.append(labels,np.ones(len(files))*idx)\n",
        "        idx += 1\n",
        "assert len(labels)!=0, '[Error] No data provided.'\n",
        "\n",
        "print('Done.')\n",
        "\n",
        "print(\"Total nombres d'images importés: {:d}\".format(len(labels)))\n",
        "\n",
        "nbof_classes = len(np.unique(labels))\n",
        "print('Total nombre de classes: {:d}'.format(nbof_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lycM4PilF3Kz",
        "outputId": "1fc909ad-1103-4144-c98f-b07496dbe2a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre d'images d'entrainements:  3899\n",
            "Number de classes d'entrainements:  313\n",
            "Number d'images de test:  890\n",
            "Number de classes de test:  134\n"
          ]
        }
      ],
      "source": [
        "nbof_test = int(VALID_SPLIT*nbof_classes)\n",
        "\n",
        "keep_test = np.less(labels,nbof_test)\n",
        "keep_train = np.logical_not(keep_test)\n",
        "\n",
        "filenames_test = filenames[keep_test]\n",
        "labels_test = labels[keep_test]\n",
        "\n",
        "filenames_train = filenames[keep_train]\n",
        "labels_train = labels[keep_train]\n",
        "\n",
        "print(\"Nombre d'images d'entrainements: \" , len(filenames_train))\n",
        "print(\"Number de classes d'entrainements: \" ,nbof_classes-nbof_test)\n",
        "print(\"Number d'images de test: \" ,len(filenames_test))\n",
        "print(\"Number de classes de test: \" ,nbof_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Définition fonction de perte et calcul accuracy\n"
      ],
      "metadata": {
        "id": "GBxy2mx_f5-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu5FFss6F3K0"
      },
      "outputs": [],
      "source": [
        "alpha = 0.3\n",
        "def triplet(y_true,y_pred):\n",
        "    \n",
        "    a = y_pred[0::3]\n",
        "    p = y_pred[1::3]\n",
        "    n = y_pred[2::3]\n",
        "    \n",
        "    ap = K.sum(K.square(a-p),-1)\n",
        "    an = K.sum(K.square(a-n),-1)\n",
        "\n",
        "    return K.sum(tf.nn.relu(ap - an + alpha))\n",
        "\n",
        "def triplet_acc(y_true,y_pred):\n",
        "    a = y_pred[0::3]\n",
        "    p = y_pred[1::3]\n",
        "    n = y_pred[2::3]\n",
        "    \n",
        "    ap = K.sum(K.square(a-p),-1)\n",
        "    an = K.sum(K.square(a-n),-1)\n",
        "    \n",
        "    return K.less(ap+alpha,an)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Définition du modèle\n"
      ],
      "metadata": {
        "id": "Gy9SS0GxgAX5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTAL6FghF3K0",
        "outputId": "ea08c69e-6a9b-47ea-b284-f894b632de74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definition du modèle whaleFaceNet ...\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Add, GlobalAveragePooling2D, DepthwiseConv2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda, BatchNormalization\n",
        "\n",
        "\"\"\"\n",
        "Model numero présenté dans le papier avec le dropout et sans les \"bottlneck layers\"\n",
        "\"\"\"\n",
        "\n",
        "print('Definition du modèle {:s} ...'.format(NET_NAME))\n",
        "\n",
        "# 128 meilleure choix de taille d'embedding en général voir le papier de recherche\n",
        "emb_size = 32\n",
        "\n",
        "### définition de l'architecture du modèle\" ###\n",
        "\n",
        "inputs = Input(shape=SIZE)\n",
        "x = Conv2D(16, (7, 7), (2, 2), use_bias=False, activation='relu', padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((3,3))(x)\n",
        "\n",
        "for layer in [16,32,64,128,512]:\n",
        "  x = Conv2D(layer, (3, 3), strides=(2,2), use_bias=False, activation='relu', padding='same')(x)\n",
        "  r = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(layer, (3, 3), use_bias=False, activation='relu', padding='same')(r)\n",
        "  x = BatchNormalization()(x)\n",
        "  r = Add()([r,x])\n",
        "\n",
        "  x = Conv2D(layer, (3, 3), use_bias=False, activation='relu', padding='same')(r)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Add()([r,x])\n",
        "    \n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(emb_size, use_bias=False)(x)\n",
        "outputs = Lambda(lambda x: tf.nn.l2_normalize(x,axis=-1))(x)\n",
        "\n",
        "model = tf.keras.Model(inputs,outputs)\n",
        "\n",
        "\n",
        "### compilation model ###\n",
        "\n",
        "model.compile(loss=triplet,\n",
        "            optimizer='adam',\n",
        "            metrics=[triplet_acc])\n",
        "\n",
        "print('Done.')\n",
        "\n",
        "#print(model.summary())\n",
        "\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "# sauvegarde de l'architecture du réseau dans un fichier texte\n",
        "with open('modelsummary.txt', 'w') as f:\n",
        "  with redirect_stdout(f):\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Helper Functions\n",
        "le preprocessing comme le resize normalisation sont effectués au sein de la fonction load_image"
      ],
      "metadata": {
        "id": "8VhR4VW3gKb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "def define_adaptive_hard_triplets_batch(filenames,labels,predict,nbof_triplet=21*3, use_neg=True, use_pos=True):\n",
        "    \"\"\"\n",
        "    Genere des \"hard triplets\" pour la \"offline selection\" \n",
        "    On va considerer tout le dataset filenames (qui est un subset)\n",
        "    La fonction va retourner les valeurs predites    \n",
        "    Args:\n",
        "        -images: images from which the triplets will be created\n",
        "        -labels: labels des images\n",
        "        -predict: embeddings predits pour les images par le model entrainé\n",
        "        -alpha: seuil pour la fonction de perte\n",
        "    Returns:\n",
        "        -triplets\n",
        "        -y_triplets: label des triplets\n",
        "        -pred_triplets: embedding prédit pour le triplet\n",
        "    \"\"\"\n",
        "    # Check if we have the right number of triplets\n",
        "    assert nbof_triplet%3 == 0\n",
        "    \n",
        "    # on récupère l'indice des classes du subset de fichiers envoyé en paramètre\n",
        "    _,idx_classes = np.unique(labels,return_index=True)\n",
        "    classes = labels[np.sort(idx_classes)]\n",
        "   \n",
        "    triplets = []\n",
        "    y_triplets = np.empty(nbof_triplet)\n",
        "    pred_triplets = np.empty((nbof_triplet,predict.shape[-1]))\n",
        "    for i in range(0,nbof_triplet,3):\n",
        "        # Chooses the first class randomly\n",
        "        keep = np.equal(labels,classes[np.random.randint(len(classes))])\n",
        "        keep_filenames = filenames[keep]\n",
        "        keep_labels = labels[keep]\n",
        "        \n",
        "        # Chooses the first image among this class randomly\n",
        "        idx_image1 = np.random.randint(len(keep_labels))\n",
        "        \n",
        "        # Computes the distance between the chosen image and the rest of the class\n",
        "        if use_pos:\n",
        "            dist_class = np.sum(np.square(predict[keep]-predict[keep][idx_image1]),axis=-1)\n",
        "\n",
        "            idx_image2 = np.argmax(dist_class)\n",
        "        else:\n",
        "            idx_image2 = np.random.randint(len(keep_labels))\n",
        "            j = 0\n",
        "            while idx_image1==idx_image2:\n",
        "                idx_image2 = np.random.randint(len(keep_labels))\n",
        "                # Just to prevent endless loop:\n",
        "                j += 1\n",
        "                if j == 1000:\n",
        "                    print(\"[Error: define_hard_triplets_batch] Endless loop.\")\n",
        "                    break\n",
        "        \n",
        "        triplets += [keep_filenames[idx_image1]]\n",
        "        y_triplets[i] = keep_labels[idx_image1]\n",
        "        pred_triplets[i] = predict[keep][idx_image1]\n",
        "        triplets += [keep_filenames[idx_image2]]\n",
        "        y_triplets[i+1] = keep_labels[idx_image2]\n",
        "        pred_triplets[i+1] = predict[keep][idx_image2]\n",
        "        \n",
        "        # Computes the distance between the chosen image and the rest of the other classes\n",
        "        not_keep = np.logical_not(keep)\n",
        "        \n",
        "        if use_neg:\n",
        "            dist_other = np.sum(np.square(predict[not_keep]-predict[keep][idx_image1]),axis=-1)\n",
        "            idx_image3 = np.argmin(dist_other) \n",
        "        else:\n",
        "            idx_image3 = np.random.randint(len(filenames[not_keep]))\n",
        "            \n",
        "        triplets += [filenames[not_keep][idx_image3]]\n",
        "        y_triplets[i+2] = labels[not_keep][idx_image3]\n",
        "        pred_triplets[i+2] = predict[not_keep][idx_image3]\n",
        "\n",
        "    return np.array(triplets), y_triplets, pred_triplets\n",
        "\n",
        "\n",
        "\n",
        "def define_triplets_batch(filenames,labels,nbof_triplet = 21 * 3):\n",
        "    \"\"\"\n",
        "    Generates offline soft triplet.\n",
        "    Given a list of file names of pictures, their specific label and\n",
        "    a number of triplet images, returns an array of triplet of images\n",
        "    and their specific labels.\n",
        "\n",
        "    Args:\n",
        "     - filenames: array of strings. List of file names of the pictures. \n",
        "     - labels: array of integers.\n",
        "     - nbof_triplet: integer. Has to be a multiple of 3.\n",
        "     \n",
        "     Returns:\n",
        "     - triplet_train: array of pictures --> a 4D array. \n",
        "     - y_triplet: array of integers of same dimension as the first\n",
        "     dimension of triplet_train. Contains the labels of the pictures.\n",
        "    \"\"\"\n",
        "    triplet_train = []\n",
        "    y_triplet = np.empty(nbof_triplet)\n",
        "    classes = np.unique(labels)\n",
        "    for i in range(0,nbof_triplet,3):\n",
        "        # Pick a class and chose two pictures from this class\n",
        "        classAP = classes[np.random.randint(len(classes))]\n",
        "        keep = np.equal(labels,classAP)\n",
        "        keep_classAP = filenames[keep]\n",
        "        keep_classAP_idx = labels[keep]\n",
        "        idx_image1 = np.random.randint(len(keep_classAP))\n",
        "        idx_image2 = np.random.randint(len(keep_classAP))\n",
        "        while idx_image1 == idx_image2:\n",
        "            idx_image2 = np.random.randint(len(keep_classAP))\n",
        "\n",
        "        triplet_train += [keep_classAP[idx_image1]]\n",
        "        triplet_train += [keep_classAP[idx_image2]]\n",
        "        y_triplet[i] = keep_classAP_idx[idx_image1]\n",
        "        y_triplet[i+1] = keep_classAP_idx[idx_image2]\n",
        "        # Pick a class for the negative picture\n",
        "        classN = classes[np.random.randint(len(classes))]\n",
        "        while classN==classAP:\n",
        "            classN = classes[np.random.randint(len(classes))]\n",
        "        keep = np.equal(labels,classN)\n",
        "        keep_classN = filenames[keep]\n",
        "        keep_classN_idx = labels[keep]\n",
        "        idx_image3 = np.random.randint(len(keep_classN))\n",
        "        triplet_train += [keep_classN[idx_image3]]\n",
        "        y_triplet[i+2] = keep_classN_idx[idx_image3]\n",
        "        \n",
        "    return triplet_train, y_triplet\n",
        "\n",
        "\n",
        "\n",
        "def image_generator(filenames, labels, batch_size=63):\n",
        "    \"\"\"\n",
        "    Training generator for soft triplets.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        f_triplet, y_triplet = define_triplets_batch(filenames, labels, batch_size)\n",
        "        i_triplet = load_images(f_triplet)\n",
        "        yield (i_triplet, y_triplet)\n",
        "\n",
        "\n",
        "\n",
        "def load_images(filenames):\n",
        "    \"\"\"\n",
        "    Recupère les images à partir du nom de fichier la converty en np array et la normalise.\n",
        "    \"\"\"\n",
        "    h,w,c = SIZE\n",
        "    \n",
        "    images = np.empty((len(filenames),h,w,c))\n",
        "\n",
        "    for i,f in enumerate(filenames):\n",
        "        img = sk.io.imread(f)/255.0\n",
        "        img = resize(img, (h,w),anti_aliasing=True)\n",
        "        images[i] = img/255.0\n",
        "    return images\n",
        "\n",
        "\n",
        "\n",
        "def predict_generator(filenames, batch_size=32):\n",
        "    \"\"\"\n",
        "    Prediction generator.\n",
        "    \"\"\"\n",
        "    for i in range(0,len(filenames),batch_size):\n",
        "        images_batch = load_images(filenames[i:i+batch_size])\n",
        "        yield images_batch\n",
        "\n",
        "\n",
        "\n",
        "def online_adaptive_hard_image_generator(\n",
        "    filenames,                  # Absolute path of the images\n",
        "    labels,                     # Labels des images\n",
        "    model,                      # A keras model\n",
        "    loss,                       # Current loss of the model\n",
        "    batch_size      =63,        # Batch size (has to be a multiple of 3 for WhaleFaceNet)\n",
        "    nbof_subclasses =10):       # Nombres de sous classes ou les triples vont être selectionné\n",
        "    \"\"\"\n",
        "    Generator to select online hard triplets for training.\n",
        "    Include an adaptive control on the number of hard triplets included during the training.\n",
        "    \"\"\"\n",
        "    \n",
        "    hard_triplet_ratio = 0\n",
        "    nbof_hard_triplets = 0\n",
        "    while True:\n",
        "        # Selection d'un certain de nombres de subclasses\n",
        "        classes = np.unique(labels)\n",
        "        \"\"\"\n",
        "        Pour limiter la nombre de calcul lors de la predition on ne va pas \n",
        "        calculer nbof_subclasses predictions pour la generation des hard triplets\n",
        "        mais calculer un nombre directement impacté par le valeur de l'accuracy.\n",
        "        Plus l'accuracy est elevé plus on va chercher à generer de hard triplets \n",
        "        Ainsi on va en génerer int(nbof_subclasses*hard_triplet_ratio)+2.\n",
        "        \"\"\"\n",
        "        # on récupère les sous classes aléatoirement on en choissisant un nombre linéairement lié au hard_triplet_ratio \n",
        "        subclasses = np.random.choice(classes,size=int(nbof_subclasses*hard_triplet_ratio)+2,replace=False)\n",
        "        # keep_classes est un masque sur les labels à garder\n",
        "        keep_classes = np.equal(labels,subclasses[0])\n",
        "        for i in range(1,len(subclasses)):\n",
        "            keep_classes = np.logical_or(keep_classes,np.equal(labels,subclasses[i]))\n",
        "\n",
        "        subfilenames = filenames[keep_classes]\n",
        "        sublabels = labels[keep_classes]\n",
        "\n",
        "        # prédictions sur les fichiers et labels à conserver\n",
        "        predict = model.predict(predict_generator(subfilenames, 32),\n",
        "                                          steps=int(np.ceil(len(subfilenames)/32)))\n",
        "\n",
        "        # \n",
        "        f_triplet_hard, y_triplet_hard, predict_hard = define_adaptive_hard_triplets_batch(subfilenames, sublabels, predict, nbof_hard_triplets*3, use_neg=True, use_pos=True)\n",
        "        f_triplet_soft, y_triplet_soft, predict_soft = define_adaptive_hard_triplets_batch(subfilenames, sublabels, predict, batch_size-nbof_hard_triplets*3, use_neg=False, use_pos=False)\n",
        "\n",
        "        f_triplet = np.append(f_triplet_hard,f_triplet_soft)\n",
        "        y_triplet = np.append(y_triplet_hard,y_triplet_soft)\n",
        "\n",
        "        predict = np.append(predict_hard, predict_soft, axis=0)\n",
        "        \n",
        "        # Proportion de hard triplets dans le batch generé\n",
        "        # hard_triplet_ratio = max(0,1.2/(1+np.exp(-10*acc+5.3))-0.19)\n",
        "        hard_triplet_ratio = np.exp(-loss * 10 / batch_size)\n",
        "\n",
        "        if isnan(hard_triplet_ratio):\n",
        "            hard_triplet_ratio = 0\n",
        "        nbof_hard_triplets = int(batch_size//3 * hard_triplet_ratio)\n",
        "        \n",
        "        i_triplet = load_images(f_triplet)\n",
        "        \n",
        "        yield (i_triplet, y_triplet)"
      ],
      "metadata": {
        "id": "IoeK-6ANev43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7BDzCUYF3K5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6398e2-f4d4-4129-c7e9-5e86065cc6e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from output/model/whaleFaceNet.9.h5 ...\n",
            "Done.\n",
            "Beginning epoch number: 9\n",
            "Current hard triplet ratio: 0.8187307530779818\n",
            "150/150 [==============================] - 4007s 27s/step - loss: 4.3652 - triplet_acc: 0.1927 - val_loss: 2.4805 - val_triplet_acc: 0.0267\n",
            "Beginning epoch number: 10\n",
            "Current hard triplet ratio: 0.2333855058876403\n",
            " 41/150 [=======>......................] - ETA: 14:20 - loss: 3.8794 - triplet_acc: 0.2268"
          ]
        }
      ],
      "source": [
        "from skimage import io\n",
        "\n",
        "# Model training.\n",
        "histories = []\n",
        "crt_loss = 0.6\n",
        "crt_acc = 0\n",
        "batch_size = 3*10\n",
        "nbof_subclasses = 40\n",
        "\n",
        "# Create saving folders\n",
        "if not os.path.isdir(PATH_MODEL):\n",
        "    os.makedirs(PATH_MODEL)\n",
        "if not os.path.isdir(PATH_SAVE):\n",
        "    os.makedirs(PATH_SAVE)\n",
        "\n",
        "# Bug fixed: keras models are to be initialized by a training on a single batch\n",
        "for images_batch,labels_batch in online_adaptive_hard_image_generator(\n",
        "    filenames_train,\n",
        "    labels_train,\n",
        "    model,\n",
        "    crt_acc,\n",
        "    batch_size = batch_size,\n",
        "    nbof_subclasses=nbof_subclasses):\n",
        "    h = model.train_on_batch(images_batch,labels_batch)\n",
        "    break\n",
        "\n",
        "if START_EPOCH > 0:\n",
        "  print('Loading model from {:s}{:s}.{:d}.h5 ...'.format(PATH_MODEL,NET_NAME,START_EPOCH))\n",
        "\n",
        "  model = tf.keras.models.load_model(\n",
        "      '{:s}{:s}.{:d}.h5'.format(PATH_MODEL,NET_NAME,START_EPOCH),\n",
        "      custom_objects={'triplet':triplet,'triplet_acc':triplet_acc})\n",
        "\n",
        "  print('Done.')\n",
        "\n",
        "for i in range(START_EPOCH,START_EPOCH+NBOF_EPOCHS):\n",
        "    print(\"Beginning epoch number: \"+str(i))\n",
        "\n",
        "    hard_triplet_ratio = np.exp(-crt_loss * 10 / batch_size)\n",
        "    nbof_hard_triplets = int(batch_size//3 * hard_triplet_ratio)\n",
        "    \n",
        "    print(\"Current hard triplet ratio: \" + str(hard_triplet_ratio))\n",
        "    \n",
        "    histories += [model.fit(\n",
        "        online_adaptive_hard_image_generator(filenames_train,labels_train,model,crt_loss,batch_size,nbof_subclasses=nbof_subclasses),\n",
        "        steps_per_epoch=STEPS_PER_EPOCH,\n",
        "        epochs=1,\n",
        "        validation_data=image_generator(filenames_test,labels_test,batch_size),\n",
        "        validation_steps=VALIDATION_STEPS)]\n",
        "    \n",
        "    crt_loss = histories[-1].history['loss'][0]\n",
        "    crt_acc = histories[-1].history['triplet_acc'][0]\n",
        "\n",
        "    # Save model\n",
        "    model.save('{:s}{:s}.{:d}.h5'.format(PATH_MODEL,NET_NAME,i))\n",
        "    \n",
        "    # Save history\n",
        "    loss = np.empty(0)\n",
        "    val_loss = np.empty(0)\n",
        "    acc = np.empty(0)\n",
        "    val_acc = np.empty(0)\n",
        "\n",
        "    for history in histories:\n",
        "        loss = np.append(loss,history.history['loss'])\n",
        "        val_loss = np.append(val_loss,history.history['val_loss'])\n",
        "        acc = np.append(acc,history.history['triplet_acc'])\n",
        "        val_acc = np.append(val_acc,history.history['val_triplet_acc'])\n",
        "\n",
        "    history_ = np.array([loss,val_loss,acc,val_acc])\n",
        "    np.save('{:s}{:s}.{:d}.npy'.format(PATH_SAVE,NET_NAME,i),history_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "On génère plein de paires fausses et vraies et l'on regarde si notre modèle les classe comme appartenant au même individus ou pas (Le kernel peut être redemarrer à partir d'ici pour liberer la mémoire)"
      ],
      "metadata": {
        "id": "n5lnbesbgXRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START_EPOCH = 10\n",
        "print('Loading model from {:s}{:s}.{:d}.h5 ...'.format(PATH_MODEL,NET_NAME,START_EPOCH))\n",
        "\n",
        "model = tf.keras.models.load_model(\n",
        "    '{:s}{:s}.{:d}.h5'.format(PATH_MODEL,NET_NAME,START_EPOCH),\n",
        "    custom_objects={'triplet':triplet,'triplet_acc':triplet_acc})\n",
        "\n",
        "print('Done.')"
      ],
      "metadata": {
        "id": "XsRdmv-khfRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Verification task, pairs creation...')\n",
        "\n",
        "# nombre arbitraire mais doit être assez gros pour une valeur proche de la réalité\n",
        "NBOF_PAIRS = 15000\n",
        "#NBOF_PAIRS = len(images_test)\n",
        "\n",
        "# Create pairs\n",
        "h,w,c = SIZE\n",
        "pairs = []\n",
        "issame = np.empty(NBOF_PAIRS)\n",
        "class_test = np.unique(labels_test)\n",
        "for i in range(NBOF_PAIRS):\n",
        "    alea = np.random.rand()\n",
        "    # Pair of different dogs\n",
        "    if alea < 0.5:\n",
        "        # Choose classes:\n",
        "        class1 = np.random.randint(len(class_test))\n",
        "        class2 = np.random.randint(len(class_test))\n",
        "        while class1==class2:\n",
        "            class2 = np.random.randint(len(class_test))\n",
        "            \n",
        "        # Extract images of this class:\n",
        "        images_class1 = filenames_test[np.equal(labels_test,class1)]\n",
        "        images_class2 = filenames_test[np.equal(labels_test,class2)]\n",
        "        \n",
        "        # Chose an image amoung these selected images\n",
        "        pairs = pairs + [images_class1[np.random.randint(len(images_class1))]]\n",
        "        pairs = pairs + [images_class2[np.random.randint(len(images_class2))]]\n",
        "        issame[i] = 0\n",
        "    # Pair of same dogs\n",
        "    else:\n",
        "        # Choose a class\n",
        "        clas = np.random.randint(len(class_test))\n",
        "        images_class = filenames_test[np.equal(labels_test,clas)]\n",
        "        \n",
        "        # Select two images from this class\n",
        "        idx_image1 = np.random.randint(len(images_class))\n",
        "        idx_image2 = np.random.randint(len(images_class))\n",
        "        while idx_image1 == idx_image2:\n",
        "            idx_image2 = np.random.randint(len(images_class))\n",
        "        \n",
        "        pairs = pairs + [images_class[idx_image1]]\n",
        "        pairs = pairs + [images_class[idx_image2]]\n",
        "        issame[i] = 1\n",
        "\n",
        "print('Done.')"
      ],
      "metadata": {
        "id": "d2QQWqfWyYfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Verification task, model evaluation...')\n",
        "\n",
        "predict=model.predict(predict_generator(pairs, batch_size = 3), steps=np.ceil(len(pairs)/batch_size))\n",
        "# # Separates the pairs\n",
        "emb1 = predict[0::2]\n",
        "emb2 = predict[1::2]\n",
        "\n",
        "# # Computes distance between pairs\n",
        "diff = np.square(emb1-emb2)\n",
        "dist = np.sum(diff,1)\n",
        "dist.shape"
      ],
      "metadata": {
        "id": "-o8sFXfjSchx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best = 0\n",
        "best_t = 0\n",
        "thresholds = np.arange(0.001,4,0.001)\n",
        "for i in range(len(thresholds)):\n",
        "    less = np.less(dist, thresholds[i])\n",
        "    acc = np.logical_not(np.logical_xor(less, issame))\n",
        "    acc = acc.astype(float)\n",
        "    out = np.sum(acc)\n",
        "    out = out/len(acc)\n",
        "    if out > best:\n",
        "        best_t = thresholds[i]\n",
        "        best = out\n",
        "\n",
        "\n",
        "print('Done.')\n",
        "print(\"Best threshold: \" + str(best_t))\n",
        "print(\"Best accuracy: \" + str(best))"
      ],
      "metadata": {
        "id": "jd-dvXzgSdN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vraieP = len(issame[issame == 1])\n",
        "fausseP = len(issame[issame == 0])\n",
        "\n",
        "# Test: Look at wrong pairs\n",
        "t = best_t\n",
        "fpositifs = []\n",
        "fnegatifs = []\n",
        "vpositifs = []\n",
        "vnegatifs = []\n",
        "for i in range(len(dist)):\n",
        "    # faux positifs\n",
        "    if issame[i] == 0 and dist[i]<t:\n",
        "        fpositifs += [i]\n",
        "    # false negatifs\n",
        "    if issame[i] == 1 and dist[i]>t:\n",
        "        fnegatifs += [i]\n",
        "    # vraie positifs\n",
        "    if issame[i] == 1 and dist[i]<t:\n",
        "        vpositifs += [i]\n",
        "    # vraie negatifs\n",
        "    if issame[i] == 0 and dist[i]>t:\n",
        "        vnegatifs += [i]\n",
        "\n",
        "conf_mat = [[len(vpositifs)/vraieP,len(fnegatifs)/vraieP],[len(fpositifs)/fausseP,len(vnegatifs)/fausseP]]\n",
        "print(\"conf_matrix\")\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "bgpEBU4WSj6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Détection\n",
        "Première approches simple mais gloutonne sur la detection"
      ],
      "metadata": {
        "id": "4CPWgxWBgn8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "filenames,labels = [],[]\n",
        "for root,dirs,files in os.walk(PATH):\n",
        "    for file in files:  \n",
        "        file = root + \"/\" + file\n",
        "        dir = re.findall(\"(?<=adata\\/)(.*?)(?=\\/)\",file).pop()\n",
        "        filenames.append(file)\n",
        "        labels.append(dir)"
      ],
      "metadata": {
        "id": "7-eR2_c7S0hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "photos = 'adata/17/17.0.jpg'\n",
        "idx = filenames.index(photos)\n",
        "\n",
        "labels_bis = np.delete(labels,idx)\n",
        "filenames_bis = np.delete(filenames,idx)\n",
        "\n",
        "pairs = []\n",
        "for file in filenames_bis:\n",
        "    pairs.append(photos)\n",
        "    pairs.append(file)\n",
        "\n",
        "\n",
        "predict = model.predict(predict_generator(pairs, batch_size = 32))\n",
        "predict.shape\n",
        "\n",
        "# # # Separates the pairs\n",
        "emb1 = predict[0::2]\n",
        "emb2 = predict[1::2]\n",
        "\n",
        "# # # Computes distance between pairs\n",
        "diff = np.square(emb1-emb2)\n",
        "dist = np.sum(diff,1)\n",
        "\n",
        "labels_ = dict()\n",
        "labels_[labels[0]] = [0]\n",
        "\n",
        "tmp_classe = \"\"\n",
        "for i in range(1,len(labels)):\n",
        "    if labels[i] != labels[i-1] :\n",
        "        tmp_classe = labels[i-1]\n",
        "        labels_[tmp_classe].append(i-1)\n",
        "        tmp_classe = labels[i]\n",
        "        labels_[tmp_classe] = [i]\n",
        "        \n",
        "labels_[tmp_classe].append(len(labels)-1)\n",
        "\n",
        "dist_mean = dict()\n",
        "\n",
        "classe = np.unique(labels)\n",
        "for classe_name in classe:\n",
        "    x,y = labels_[classe_name]\n",
        "    dist_mean[classe_name] = dist[x:y].mean()\n",
        "\n",
        "print(max(dist_mean, key=dist_mean.get))"
      ],
      "metadata": {
        "id": "YOA1cZ4AS2SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A suivre \n"
      ],
      "metadata": {
        "id": "iKyhtvvVgqWu"
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "trainingFaceNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}